{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ASR\n",
    "本note计划介绍三个模块，第一模块是分步（分为声学模型（AM, acoustic model）和语言模型（LM, language model）），第二模块是end2end部分，第三个模块是目前可用的包和API\n",
    "\n",
    "## 1. AM&LM\n",
    "目前主流的声音识别模型是分为两个模块，分别是声学模型和语言模型。声学模型可以理解为对发声的建模，即把输入的语音信号转换为声学表示的输出，**准确的说是给出语音属于某一个声学符号的概率**；而语言模型的作用可以简单的理解为消解多音字的问题，在声学模型给出声学符号（发音序列）后，从候选的文字序列中找出概率最大的字符串序列。   \n",
    "基于声学模型和语言模型的连续语音识别框图如下所示，\n",
    "    ![](../../pics/speech_flow.png)\n",
    "\n",
    "整体语音识别可以表示为如下公式，\n",
    "$$\n",
    "\\begin{aligned}\n",
    "W^{*} &= \\arg \\max_w P(W|Y)\\ &(1) \\\\ \n",
    "      &= \\arg \\max_w \\frac{P(Y|W)P(W)}{P(Y)}\\ &(2) \\\\  \n",
    "      & \\thickapprox \\arg \\max_w P(Y|W)P(W)\\ &(3)\n",
    "\\end{aligned}\n",
    "$$\n",
    "其中$W$表示文字序列，$Y$表示语音输入，式(1)表示在给定语音输入的情况下，找到最大可能性（最大概率）的文字序列，式(2)通过贝叶斯公式将式(1)展开，$P(Y)$表示输入的语音出现的概率，与要预测的文字序列无关，可以忽略，从而得到式(3)，在式(3)中，$P(Y|W)$表示给定一个文字序列，出现该条语音的概率，即所说的声学模型；第二部分表示出现该文字序列的概率，即语音识别中所说的语音模型。接下来分别介绍声学模型和语言模型。\n",
    "\n",
    "### 1.1 AM(Acoustic Model)\n",
    "声学模型可以理解为是对发声的建模，它能够把语音输入转换成声学表示的输出，更准确的说是给出语音属于某个声学符号的概率。中文中，这个声学符号通常指的是拼音。  \n",
    "在声学模型$P(Y|W)$中，可以进一步通过发音单位的序列展开，\n",
    "$$\n",
    "\\begin{aligned}\n",
    "P(Y|W) &= \\arg \\max_w \\sum_Q P(Y,Q|W)\\ &(1)\\\\\n",
    "       & \\thickapprox \\arg \\max_w \\max_Q P(Y,Q|W)\\ &(2)\\\\\n",
    "       & \\thickapprox \\arg \\max_w \\max_Q P(Y|Q) P(Q|W)\\ &(3)\n",
    "\\end{aligned}\n",
    "$$\n",
    "其中$Q$表示发音单位的序列，即中文中的拼音，专业词汇称之为音素；式(1)在已知文字序列的情况下，通过发音序列$Q$将其展开，简记为式(2)，最后近似得到式(3)。   \n",
    "可以看到声学模型转化为了一个语音到发音序列的模型和发音序列到输出文字序列的字典。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.1 语音数据预处理\n",
    "整体来看，语音数据预处理是将语音数据转换为一个特征矩阵。   \n",
    "\n",
    "1) VAD   \n",
    "语音数据首先需要把首尾端的静音切除，减少干扰，这个操作称之为VAD(Voice Activity Detection)。\n",
    "\n",
    "2) 分帧   \n",
    "接来下需要对语音进行分帧，也就将语音切分为很多段，每一小段称之为帧，目前分帧操作往往不是简单的切分（损失很多信息），而是使用移动窗口函数来实现，帧与帧之间是有重叠部分，如下图所示， \n",
    "![](../../pics/split_frame.jpg)\n",
    "\n",
    "图中，每帧的长度是25ms，每两帧之间有25-10=15ms的重叠，即以帧长25ms帧移10ms进行分帧。   \n",
    "\n",
    "3) 特征提取   \n",
    "特征提取部分指将帧转换为向量。帧在时域上的描述能力较弱，因此需要将其做变换，变换的方式目前我知道的有MFCC、LPCC和FBANK，具体每一种提取方式后期补充。假设一条语音数据分帧后共有N段，每一帧提取特征后的向量维度为M，那么该条语音转换为N×M的矩阵，接下里则需要对该矩阵进行建模，将其转换为文字序列。 \n",
    "\n",
    "\n",
    "#### 1.1.2 模型\n",
    "##### 1.1.1 GMM-HMM \n",
    "\n",
    "##### 1.1.2 DNN-HMM\n",
    "\n",
    "### 1.2 LM\n",
    "## 2. end2end\n",
    "\n",
    "## 3. Package&API"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
