<h1>Table of Contents<span class="tocSkip"></span></h1>
<div class="toc"><ul class="toc-item"><li><span><a href="#1.-Data-Representation" data-toc-modified-id="1.-Data-Representation-1">1. Data Representation</a></span><ul class="toc-item"><li><span><a href="#1.1-张量介绍" data-toc-modified-id="1.1-张量介绍-1.1">1.1 张量介绍</a></span></li><li><span><a href="#1.2-张量计算" data-toc-modified-id="1.2-张量计算-1.2">1.2 张量计算</a></span><ul class="toc-item"><li><span><a href="#1.2.1-逐元素运算" data-toc-modified-id="1.2.1-逐元素运算-1.2.1">1.2.1 逐元素运算</a></span></li><li><span><a href="#1.2.2-广播" data-toc-modified-id="1.2.2-广播-1.2.2">1.2.2 广播</a></span></li><li><span><a href="#1.2.3-张量点积" data-toc-modified-id="1.2.3-张量点积-1.2.3">1.2.3 张量点积</a></span></li></ul></li></ul></li><li><span><a href="#2.-BP(Back-Propagation)" data-toc-modified-id="2.-BP(Back-Propagation)-2">2. BP(Back Propagation)</a></span><ul class="toc-item"><li><span><a href="#2.1-数据假设" data-toc-modified-id="2.1-数据假设-2.1">2.1 数据假设</a></span></li><li><span><a href="#2.2-神经网络假设" data-toc-modified-id="2.2-神经网络假设-2.2">2.2 神经网络假设</a></span></li><li><span><a href="#2.3-神经网络运行(前馈)" data-toc-modified-id="2.3-神经网络运行(前馈)-2.3">2.3 神经网络运行(前馈)</a></span></li><li><span><a href="#2.4-神经网络更新参数（反向传播，反馈）" data-toc-modified-id="2.4-神经网络更新参数（反向传播，反馈）-2.4">2.4 神经网络更新参数（反向传播，反馈）</a></span></li><li><span><a href="#2.5-具体权重更新推导" data-toc-modified-id="2.5-具体权重更新推导-2.5">2.5 具体权重更新推导</a></span></li><li><span><a href="#2.6-BP算法流程" data-toc-modified-id="2.6-BP算法流程-2.6">2.6 BP算法流程</a></span></li><li><span><a href="#2.7-BP算法额外说明" data-toc-modified-id="2.7-BP算法额外说明-2.7">2.7 BP算法额外说明</a></span></li></ul></li><li><span><a href="#3.-优化算法" data-toc-modified-id="3.-优化算法-3">3. 优化算法</a></span><ul class="toc-item"><li><span><a href="#3.1-惯性保持" data-toc-modified-id="3.1-惯性保持-3.1">3.1 惯性保持</a></span><ul class="toc-item"><li><span><a href="#3.1.1-带动量的SGD" data-toc-modified-id="3.1.1-带动量的SGD-3.1.1">3.1.1 带动量的SGD</a></span></li><li><span><a href="#3.1.2-Nesterov-动量" data-toc-modified-id="3.1.2-Nesterov-动量-3.1.2">3.1.2 Nesterov 动量</a></span></li><li><span><a href="#3.1.3-momentum和NAG的比较" data-toc-modified-id="3.1.3-momentum和NAG的比较-3.1.3">3.1.3 momentum和NAG的比较</a></span></li></ul></li><li><span><a href="#3.2-自适应学习率" data-toc-modified-id="3.2-自适应学习率-3.2">3.2 自适应学习率</a></span><ul class="toc-item"><li><span><a href="#3.2.1-AdaGrad(2011)" data-toc-modified-id="3.2.1-AdaGrad(2011)-3.2.1">3.2.1 AdaGrad(2011)</a></span></li><li><span><a href="#3.2.2-RMSProp(2012)" data-toc-modified-id="3.2.2-RMSProp(2012)-3.2.2">3.2.2 RMSProp(2012)</a></span></li><li><span><a href="#3.2.3-AdaDelta(2012)" data-toc-modified-id="3.2.3-AdaDelta(2012)-3.2.3">3.2.3 AdaDelta(2012)</a></span></li><li><span><a href="#3.2.4-Adam(2014)" data-toc-modified-id="3.2.4-Adam(2014)-3.2.4">3.2.4 Adam(2014)</a></span></li></ul></li><li><span><a href="#3.3-算法可视化" data-toc-modified-id="3.3-算法可视化-3.3">3.3 算法可视化</a></span></li><li><span><a href="#3.4-优化算法的选择" data-toc-modified-id="3.4-优化算法的选择-3.4">3.4 优化算法的选择</a></span></li><li><span><a href="#3.5-相关阅读" data-toc-modified-id="3.5-相关阅读-3.5">3.5 相关阅读</a></span></li></ul></li><li><span><a href="#4.-激活函数" data-toc-modified-id="4.-激活函数-4">4. 激活函数</a></span><ul class="toc-item"><li><span><a href="#4.1-激活函数的作用" data-toc-modified-id="4.1-激活函数的作用-4.1">4.1 激活函数的作用</a></span></li><li><span><a href="#4.2-神经网络的万能近似定理" data-toc-modified-id="4.2-神经网络的万能近似定理-4.2">4.2 神经网络的万能近似定理</a></span></li><li><span><a href="#4.3-激活函数的形象解释" data-toc-modified-id="4.3-激活函数的形象解释-4.3">4.3 激活函数的形象解释</a></span></li><li><span><a href="#4.4-常见的激活函数" data-toc-modified-id="4.4-常见的激活函数-4.4">4.4 常见的激活函数</a></span><ul class="toc-item"><li><span><a href="#4.4.1-ReLU及其扩展" data-toc-modified-id="4.4.1-ReLU及其扩展-4.4.1">4.4.1 ReLU及其扩展</a></span></li><li><span><a href="#4.4.2-Sigmoid函数" data-toc-modified-id="4.4.2-Sigmoid函数-4.4.2">4.4.2 Sigmoid函数</a></span></li><li><span><a href="#4.4.3-tanh函数" data-toc-modified-id="4.4.3-tanh函数-4.4.3">4.4.3 tanh函数</a></span></li><li><span><a href="#4.4.4-softplus函数" data-toc-modified-id="4.4.4-softplus函数-4.4.4">4.4.4 softplus函数</a></span></li><li><span><a href="#4.4.5-ReLU和Sigmoid比较" data-toc-modified-id="4.4.5-ReLU和Sigmoid比较-4.4.5">4.4.5 ReLU和Sigmoid比较</a></span></li></ul></li></ul></li><li><span><a href="#5.-正则化" data-toc-modified-id="5.-正则化-5">5. 正则化</a></span><ul class="toc-item"><li><span><a href="#5.1-批标准化(Batch-Normalization)" data-toc-modified-id="5.1-批标准化(Batch-Normalization)-5.1">5.1 批标准化(Batch Normalization)</a></span><ul class="toc-item"><li><span><a href="#5.1.1-算法原理" data-toc-modified-id="5.1.1-算法原理-5.1.1">5.1.1 算法原理</a></span></li><li><span><a href="#5.1.2-单个样本计算(移动平均)" data-toc-modified-id="5.1.2-单个样本计算(移动平均)-5.1.2">5.1.2 单个样本计算(移动平均)</a></span></li><li><span><a href="#5.1.3-为什么训练时不采用移动平均" data-toc-modified-id="5.1.3-为什么训练时不采用移动平均-5.1.3">5.1.3 为什么训练时不采用移动平均</a></span></li><li><span><a href="#5.1.4-BN的作用" data-toc-modified-id="5.1.4-BN的作用-5.1.4">5.1.4 BN的作用</a></span></li><li><span><a href="#5.1.5-BN相关阅读" data-toc-modified-id="5.1.5-BN相关阅读-5.1.5">5.1.5 BN相关阅读</a></span></li></ul></li><li><span><a href="#5.2-L1/L2正则" data-toc-modified-id="5.2-L1/L2正则-5.2">5.2 L1/L2正则</a></span></li><li><span><a href="#5.3-Dropout" data-toc-modified-id="5.3-Dropout-5.3">5.3 Dropout</a></span><ul class="toc-item"><li><span><a href="#5.3.1-训练时流程" data-toc-modified-id="5.3.1-训练时流程-5.3.1">5.3.1 训练时流程</a></span></li><li><span><a href="#5.3.2-预测时流程" data-toc-modified-id="5.3.2-预测时流程-5.3.2">5.3.2 预测时流程</a></span></li><li><span><a href="#5.3.3-dropout的作用" data-toc-modified-id="5.3.3-dropout的作用-5.3.3">5.3.3 dropout的作用</a></span></li></ul></li></ul></li><li><span><a href="#6.-References" data-toc-modified-id="6.-References-6">6. References</a></span></li></ul></div>