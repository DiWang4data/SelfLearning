{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularization（正则化）\n",
    "\n",
    "\n",
    "\n",
    "## 正则化的定义\n",
    "\n",
    "\n",
    "In mathematics, statistics, and computer science, particularly in machine learning and inverse problems, regularization is the process of adding information in order to solve an ill-posed problem or to prevent overfitting. [link](https://en.wikipedia.org/wiki/Regularization_%28mathematics%29)\n",
    "\n",
    "在机器学习中，在损失函数中添加正则项，目的是希望模型能够尽可能的拟合训练数据，同时希望得到的模型尽可能简单，防止过拟合，其形式大都如下，\n",
    "\n",
    "$$\\omega^*=\\underset{\\omega}{\\arg \\min} \\sum_i{L(y_i, f(x_i;\\omega))}+\\lambda \\Omega(\\omega) $$\n",
    "其中第一项$\\sum_i{L(y_i, f(x_i;\\omega))}$衡量模型预测值和真实值之间的损失，第二项$\\Omega(\\omega)$为正则化项，参数$\\lambda$控制正则化的强度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 回顾p-范数\n",
    "\n",
    "若向量$x \\in R^n$，令$x=[x_1, x_2, \\cdots, x_n]^T$,则向量$x$的p-范数为\n",
    "$$||x||_p=(|x_1|^p+|x_2|^p+ \\cdots +|x_n|^p)^{\\frac{1}{p}}$$\n",
    "\n",
    "当$p$取0,1,2,$\\infty$时候，  \n",
    "0-范数：$||x||_0$=向量$x$的非零元素的个数    \n",
    "1-范数: $||x||_1=|x_1|+|x_2|+ \\cdots +|x_n| $  \n",
    "2-范数：$||x||_2=(|x_1|^2+|x_2|^2+ \\cdots +|x_n|^2)^{1/2}$  \n",
    "$\\infty-$范数：$||x||_{\\infty}=\\max(|x_1|, |x_2|, \\cdots, |x_n|)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 为什么L1范数易求得稀疏解？L2范数易得到光滑解？\n",
    "\n",
    "### L0和L1   \n",
    "通常来说，若将L0范数（向量中非零元素的个数）加入到正则化项中，那么得到的解是稀疏的，但是这样做的话难以优化求解（NP-hard）。L1范数是L0范数的最优凸近似，并且它比L0范数要容易优化求解。L1范数和L0范数可以实现稀疏，L1因具有比L0更好的优化求解特性而被广泛应用\n",
    "\n",
    "### 代价函数来看\n",
    "假设只有一个参数$\\omega$，损失函数为$L(\\omega)$，加入L1和L2正则后，有\n",
    "$$J_{L_1}(\\omega)=L(\\omega)+\\lambda|\\omega|$$\n",
    "$$J_{L_2}(\\omega)=L(\\omega)+\\lambda\\omega^2$$\n",
    "\n",
    "假设$L(\\omega)$在$\\omega=0$处的导数为  \n",
    "$$\\left. \\frac{\\partial L(\\omega)}{\\partial \\omega} \\right|_{\\omega=0}=d_0$$\n",
    "则加入L1和L2正则项的导数为  \n",
    "L2： \n",
    "$$\\left. \\frac{\\partial J_{L_2}(\\omega)}{\\partial \\omega} \\right|_{\\omega=0}=d_0+2\\lambda \\omega=d_0$$\n",
    "\n",
    "L1：\n",
    "$$\n",
    " \\left. \\frac{\\partial J_{L_1}(\\omega)}{\\partial \\omega} \\right|_{\\omega=0^-}=d_0-\\lambda\n",
    "$$\n",
    "$$\n",
    " \\left. \\frac{\\partial J_{L_1}(\\omega)}{\\partial \\omega} \\right|_{\\omega=0^+}=d_0+\\lambda\n",
    "$$\n",
    "首先看L2项导数，在加入L2正则后，导数仍然为$d_0$，无变化。反观L1项导数，在$\\omega=0$处存在两个导数，$d_0-\\lambda$和$d_0+\\lambda$，若$d_0-\\lambda$和$d_0+\\lambda$异号，那么在该处会是一个极小值点，所以L1正则项更容易产生稀疏解\n",
    "\n",
    "### 优化角度   \n",
    "$L_1=|\\omega_1|+|\\omega_2|+\\cdots+|\\omega_n|, \\frac{\\partial L_1}{\\omega_i}=sign(\\omega(i))$   \n",
    "$L_2=|\\omega_1^2|+|\\omega_2^2|+\\cdots+|\\omega_n^2|, \\frac{\\partial L_2}{\\omega_i}=2\\omega_i$   \n",
    "其中，$0<\\eta<1$，另外上式中省略$L(\\omega)$，因为两者均含此项   \n",
    "以梯度下降为例，   \n",
    "L1:   \n",
    "$\\omega_i=\\omega_i-\\eta \\cdot sign(\\omega(i))$   \n",
    "从上面可以看出，当$\\omega_i>0$时，权值每次更新都固定减少一个特定值，当$\\omega_i<0$时，权值更新都固定增加一个特定值，所以综合来看，经过多次迭代，权值容易更新为0\n",
    "\n",
    "L2:   \n",
    "$\\omega_i=\\omega_i-\\eta \\cdot 2\\omega_i=(1-2\\eta)\\omega_i$   \n",
    "从上面可以看出$\\omega_i$的减少是按比例进行减少，所以不易收敛到0，但是会更新到一个较小的值\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 参考资源\n",
    "\n",
    "[1]. https://en.wikipedia.org/wiki/Regularization_%28mathematics%29    \n",
    "[2]. https://blog.csdn.net/zouxy09/article/details/24971995    \n",
    "[3]. https://www.cnblogs.com/Rvin/p/10076258.html    \n",
    "[4]. https://blog.csdn.net/li8zi8fa/article/details/77649973    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
